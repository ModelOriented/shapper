% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/shap_feture_importance.R
\name{shap_feature_importance}
\alias{shap_feature_importance}
\alias{shap}
\alias{shap_feature_importance.explainer}
\alias{shap_feature_importance.default}
\title{SHAP Feature Importance
Calculates SHAP feature importance values. SHAP values are calculated for each instance of the given data. 
The mean of the absolute SHAP values for each feature is then returned.
(See Molnar 2020: https://christophm.github.io/interpretable-ml-book/shap.html#shap-feature-importance)

Implements the kmeans function of the SHAP python lib to help summarize large data sets.}
\usage{
shap_feature_importance(x, ...)

\method{shap_feature_importance}{explainer}(
  x,
  method = "KernelSHAP",
  nsamples = "auto",
  kmeans = FALSE,
  k = 150,
  ...
)

\method{shap_feature_importance}{default}(
  x,
  data,
  predict_function = predict,
  label = tail(class(x), 1),
  method = "KernelSHAP",
  nsamples = "auto",
  kmeans = FALSE,
  k = 150,
  ...
)
}
\arguments{
\item{x}{a model to be explained, or an explainer created with function \code{\link[DALEX]{explain}}.}

\item{...}{other parameters.}

\item{method}{an estimation method of SHAP values. Currently the only availible is `KernelSHAP`.}

\item{nsamples}{number of samples or "auto". Note that number must be as integer. Use `as.integer()`.}

\item{kmeans}{(bool) activate summarizing the dataset to decrease background data sample size for increased performance.}

\item{k}{number of summary instances generated through kmeans}

\item{data}{validation dataset. Used to determine univariate distributions, calculation of quantiles,
correlations and so on. It will be extracted from `x` if it’s an explainer.}

\item{predict_function}{predict function that operates on the model `x`. Since the model is a black box,
the `predict_function` is the only interface to access values from the model. It should be a function that
takes at least a model `x` and data and returns vector of predictions. If model response has more than
a single number (like multiclass models) then this function should return a marix/data.frame of the size
`m` x `d`, where `m` is the number of observations while `d` is the dimensionality of model response.
It will be extracted from `x` if it’s an explainer.}

\item{label}{name of the model. By default it’s extracted from the class attribute of the model}
}
\value{
A named vector of feature importance values

In order to use shapper with other python virtual environment following R command are required to execute
reticulate::use_virtualenv("path_to_your_env")
or for conda
reticulate::use_conda("name_of_conda_env")
before attaching shapper.
}
\description{
SHAP Feature Importance
Calculates SHAP feature importance values. SHAP values are calculated for each instance of the given data. 
The mean of the absolute SHAP values for each feature is then returned.
(See Molnar 2020: https://christophm.github.io/interpretable-ml-book/shap.html#shap-feature-importance)

Implements the kmeans function of the SHAP python lib to help summarize large data sets.
}
